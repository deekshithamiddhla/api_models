{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYuD5v3dzIGq",
        "outputId": "4faced6d-e18d-4f08-9b2a-be792d819f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langChain\n",
            "  Downloading langchain-0.0.266-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langChain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langChain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langChain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langChain) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langChain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.21 (from langChain)\n",
            "  Downloading langsmith-0.0.22-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langChain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langChain) (1.23.5)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langChain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2,>=1 (from langChain)\n",
            "  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langChain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langChain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langChain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langChain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langChain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langChain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langChain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langChain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langChain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langChain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langChain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langChain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langChain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langChain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langChain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langChain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langChain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: pydantic, mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langsmith, dataclasses-json, langChain\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.1.1\n",
            "    Uninstalling pydantic-2.1.1:\n",
            "      Successfully uninstalled pydantic-2.1.1\n",
            "Successfully installed dataclasses-json-0.5.14 langChain-0.0.266 langsmith-0.0.22 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 pydantic-1.10.12 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting faiss_cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss_cpu\n",
            "Successfully installed faiss_cpu-1.7.4\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langChain\n",
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install faiss_cpu\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "ilVCvAiVzaXk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]=\"sk-dmWO8PnfXmEXeKT3BlbkFJulCdllxl0zcCMeI1BTBA\""
      ],
      "metadata": {
        "id": "JPHQSV2YzaUu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PROVIDE THE PATH OF PDF FILE.\n",
        "pdfreader=PdfReader('/content/SSRN_R1.pdf')"
      ],
      "metadata": {
        "id": "jx39vI8lzaR2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "#read text from pdf\n",
        "raw_text=\"\"\n",
        "for i,page in enumerate(pdfreader.pages):\n",
        "  content=page.extract_text()\n",
        "  if content:\n",
        "    raw_text += content"
      ],
      "metadata": {
        "id": "YwmRRofWzaPP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "xJF7Lg_QzaMS",
        "outputId": "53ee6c8f-afab-43f8-cd6e-a61e5c8a6cb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/370653602\\nGenerative AI\\nPreprint  · May 2023\\nCITATIONS\\n0READS\\n6,160\\n4 author s, including:\\nSome o f the author s of this public ation ar e also w orking on these r elat ed pr ojects:\\nDesign Theories  View pr oject\\nBusiness Analytics and R eal-time Pr ocess Analytics  View pr oject\\nJochen Hartmann\\nTechnische Univ ersität München\\n24 PUBLICA TIONS \\xa0\\xa0\\xa0484 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nPatrick Zschech\\nFriedrich-Ale xander -Univ ersity of Erlang en-Nürnber g\\n66 PUBLICA TIONS \\xa0\\xa0\\xa0969 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Patrick Zschech  on 31 July 2023.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.Generative AI\\nStefan Feuerriegel1,∗and Jochen Hartmann2and Christian Janiesch3and Patrick Zschech4\\n1LMU Munich & Munich Center for Machine Learning, Geschwister-Scholl-Platz 1, 80539 Munich,\\nfeuerriegel@lmu.de\\n2Technical University of Munich, TUM School of Management, Arcisstr. 21, 80333 Munich,\\njochen.hartmann@tum.de\\n3TU Dortmund University, Otto-Hahn-Str. 12, 44319 Dortmund, christian.janiesch@tu-dortmund.de\\n4FAU Erlangen-Nürnberg, Lange Gasse 20, 90403 Nürnberg, patrick.zschech@fau.de\\n∗To whom correspondence should be addressed; e-mail: feuerriegel@lmu.de.\\nKeywords: Generative AI; Artiﬁcial intelligence; Decision support; Content creation; In-\\nformation systems\\n1 Introduction\\nTom Freston is credited with saying “Innovation is taking two things that exist and putting them together\\nin a new way”. For a long time in history, it has been the prevailing assumption that artistic, creative\\ntasks such as writing poems, creating software, designing fashion, and composing songs could only\\nbe performed by humans. This assumption has changed drastically with recent advances in artiﬁcial\\nintelligence (AI) that can generate new content in ways that cannot be distinguished anymore from human\\ncraftsmanship.\\nThe term generative AI refers to computational techniques that are capable of generating seemingly\\nnew, meaningful content such as text, images, or audio from training data. The widespread diffusion\\nof this technology with examples such as Dall-E 2, GPT-4, and Copilot is currently revolutionizing the\\nway we work and communicate with each other. Generative AI systems can not only be used for artis-\\ntic purposes to create new text mimicking writers or new images mimicking illustrators, but they can\\nand will assist humans as intelligent question-answering systems. Here, applications include informa-\\ntion technology (IT) help desks where generative AI supports transitional knowledge work tasks and\\nmundane needs such as cooking recipes and medical advice. Industry reports suggest that generative\\nAI could raise global gross domestic product (GDP) by 7% and replace 300 million jobs of knowledge\\nworkers ( Goldman Sachs ,2023 ). Undoubtedly, this has drastic implications not only for the Business\\n& Information Systems Engineering (BISE) community, where we will face revolutionary opportunities,\\n1but also challenges and risks that we need to tackle and manage to steer the technology and its use in a\\nresponsible and sustainable direction.\\nIn this Catchword article, we provide a conceptualization of generative AI as an entity in socio-\\ntechnical systems and provide examples of models, systems, and applications. Based on that, we in-\\ntroduce limitations of current generative AI and provide an agenda for BISE research. Previous papers\\ndiscuss generative AI around speciﬁc methods such as language models (e.g., Dwivedi et al. ,2023 ;Schö-\\nbel et al. ,2023 ;Teubner et al. ,2023 ) or speciﬁc applications such as marketing (e.g., Peres et al. ,2023 ),\\ninnovation management ( Burger et al. ,2023 ), scholarly research (e.g., Davison et al. ,2023 ;Susarla et al. ,\\n2023 ), and education (e.g., Gimpel et al. ,2023 ;Kasneci et al. ,2023 ). Different from these works, we\\nfocus on generative AI in the context of information systems, and, to this end, we discuss several op-\\nportunities and challenges that are unique to the BISE community and make suggestions for impactful\\ndirections for BISE research.\\n2 Conceptualization\\n2.1 Mathematical Principles of Generative AI\\nGenerative AI is primarily based on generative modeling, which has distinctive mathematical differences\\nfrom discriminative modeling ( Ng and Jordan ,2001 ) often used in data-driven decision support. In gen-\\neral, discriminative modeling tries to separate data points Xinto different classes Yby learning decision\\nboundaries between them (e.g., in classiﬁcation tasks with Y∈ {0,1}). In contrast to that, generative\\nmodeling aims to infer some actual data distribution. Examples can be the joint probability distribution\\nP(X,Y)of both the inputs and the outputs or P(Y), but where Yis typically from some high-dimensional\\nspace. By doing so, a generative model offers the ability to produce new synthetic samples (e.g., generate\\nnew observation-target-pairs (X,Y)or new observations Xgiven a target value Y) (Bishop ,2006 ).\\nBuilding upon the above, a generative AI model refers to generative modeling that is instantiated\\nwith a machine learning architecture (e.g., a deep neural network) and, therefore, can create new data\\nsamples based on learned patterns.1Further, a generative AI system encompasses the entire infrastruc-\\nture, including the model, data processing, and user interface components. The model serves as the core\\n1It should be noted, however, that advanced generative AI models are often not based on a single modeling principle or\\nlearning mechanism, but combine different approaches. For example, language models from the GPT family ﬁrst apply a gen-\\nerative pre-training stage to capture the distribution of language data using a language modeling objective, while downstream\\nsystems typically then apply a discriminative ﬁne-tuning stage to adapt the model parameters to speciﬁc tasks (e.g., docu-\\nment classiﬁcation, question answering). Similarly, ChatGPT combines techniques from generative modeling together with\\ndiscriminatory modeling and reinforcement learning (see Figure 2).\\n2component of the system, which facilitates interaction and application within a broader context. Lastly,\\ngenerative AI applications refer to the practical use cases and implementations of these systems, such as\\nsearch engine optimization (SEO) content generation or code generation that solve real-world problems\\nand drive innovation across various domains. Figure 1shows a systematization of generative AI across\\nselected data modalities (e.g., text, image, and audio) and the model-, system-, and application-level\\nperspectives, which we detail in the following section.\\nModel                     \\nlevelSystem          \\nlevelApplication    \\nlevel\\nT ext \\nGeneration\\nImage/Video \\nGeneration\\nSpeech/Music \\nGeneration\\nCode \\nGenerationX-to-text models, e.g., \\nGPT-4 and LLaMA 2Conversational agents \\nand search engines, e.g., \\nChatGPT and YouChat•Content generation (e.g., \\nSEO and customer service)\\n•Translation and text \\nsummarization\\nX-to-image models, \\ne.g., Stable Diffusion \\nand DALL -E 2Image/video generation \\nsystems and bots, e.g., \\nRunway and Midjourney•Synthetic product and \\nadvertising visuals\\n•Educational content\\nX-to-code models, e.g., \\nCodex and AlphaCode•Software development\\n•Code synthesis, review, \\nand documentationX-to-music/speech \\nmodels, e.g., MusicLM \\nand VALL -ESpeech generation \\nsystems, e.g., ElevenLabs•AI music generation\\n•Text-to-speech \\ngeneration (e.g., news, \\nproduct tutorials, etc.)\\nProgramming code \\ngeneration systems, \\ne.g., GitHub CopilotUnderlying AI model  for \\ndifferent data  modalities  \\n(e.g., image , text, code)Embedding model  \\nfunctionality  to provide  \\ninterface for interactionSolving  dedicated  \\nbusiness  problems  \\nand stakeholder  needsOutput \\nModality (Selection)\\nFigure 1: A model-, system-, and application-level view on generative AI.\\nNote that the modalities in Figure 1are neither complete nor entirely distinctive and can be detailed\\nfurther. In addition, many unique use cases such as, for example, modeling functional properties of\\nproteins ( Unsal et al. ,2022 ) can be represented in another modality such as text.\\n2.2 A Model-, System-, and Application-Level View of Generative AI\\n2.2.1 Model-Level View\\nA generative AI model is a type of machine learning architecture that uses AI algorithms to create novel\\ndata instances, drawing upon the patterns and relationships observed in the training data. A generative\\nAI model is of critically central yet incomplete nature, as it requires further ﬁne-tuning to speciﬁc tasks\\nthrough systems and applications.\\nDeep neural networks are particularly well suited for the purpose of data generation, especially as\\ndeep neural networks can be designed using different architectures to model different data types ( Janiesch\\n3et al. ,2021 ;Kraus et al. ,2020 ), for example, sequential data such as human language or spatial data\\nsuch as images. Table 1presents an overview of the underlying concepts and model architectures that\\nare common in the context of generative AI, such as diffusion probabilistic models for text-to-image\\ngeneration or the transformer architecture and (large) language models (LLMs) for text generation. GPT\\n(short for generative pre-trained transformer), for example, represents a popular family of LLMs, used\\nfor text generation, for instance, in the conversational agent ChatGPT.\\nLarge generative AI models that can model output in and across speciﬁc domains or speciﬁc data\\ntypes in a comprehensive and versatile manner are oftentimes also called foundation models (Bom-\\nmasani et al. ,2021 ). Due to their size, they exhibit two key properties: emergence , meaning the behavior\\nis oftentimes implicitly induced rather than explicitly constructed (e.g., GPT models can create calendar\\nentries in the .ical format even though such models were not explicitly trained to do so), and homoge-\\nnization , where a wide range of systems and applications can now be powered by a single, consolidated\\nmodel (e.g., Copilot can generate source code across a wide range of programming languages).\\nFigure 1presents an overview of generative AI models along different, selected data modalities,\\nwhich are pre-trained on massive amounts of data. Note that we structure the models in Figure 1by\\ntheir output modality such as X-to-text or X-to-image. For example, GPT-4 as the most recent generative\\nAI model underlying OpenAI’s popular conversational agent ChatGPT ( OpenAI ,2023a ) accepts both\\nimage and text inputs to generate text outputs. Similarly, Midjourney accepts both modalities to generate\\nimages. To this end, generative AI models can also be grouped into unimodal and multimodal models.\\nUnimodal models take instructions from the same input type as their output (e.g., text). On the other\\nhand, multimodal models can take input from different sources and generate output in various forms.\\nMultimodal models exist across a variety of data modalities, for example for text, image, and audio.\\nProminent examples include Stable Diffusion ( Rombach et al. ,2022 ) for text-to-image generation, Mu-\\nsicLM ( Agostinelli et al. ,2023 ) for text-to-music generation, Codex ( Chen et al. ,2021 ) and AlphaCode\\n(Li et al. ,2022 ) for text-to-code generation, and as mentioned above GPT-4 for image-to-text as well as\\ntext-to-text generation ( OpenAI ,2023a ).\\nThe underlying training procedures vary greatly across different generative AI models (see Figure 2).\\nFor example, generative adversarial networks (GANs) are trained through two competing objectives\\n(Goodfellow et al. ,2014 ), where one is to create new synthetic samples while the other tries to detect\\nsynthetic samples from the actual training samples, so that the distribution of synthetic samples is even-\\n4tually close to the distribution of the training samples. Differently, systems such as ChatGPT-based\\nconversational models use reinforcement learning from human feedback (RLHF). RLHF as used by\\nChatGPT proceeds in three steps to ﬁrst create demonstration data for prompts, then to have users rank\\nthe quality of different outputs for a prompt, and ﬁnally to learn a policy that generates desirable output\\nvia reinforcement learning so that the output would score well during ranking ( Ziegler et al. ,2019 ).\\nConcept Description\\nDiffusion probabilistic models Diffusion probability models are a class of latent variable models that are common for various tasks such as image generation ( Ho et al. ,2020 ).\\nFormally, diffusion probability models capture the image data by modeling the way data points diffuse through a latent space, which is inspired\\nby statistical physics. Speciﬁcally, they typically use Markov chains trained with variational inference and then reverse the diffusion process to\\ngenerate a natural image. A notable variant is Stable Diffusion ( Rombach et al. ,2022 ). Diffusion probability models are also used in commercial\\nsystems such as DALL-E and Midjourney.\\nGenerative adversarial network A GAN is a class of neural network architecture with a custom, adversarial learning objective ( Goodfellow et al. ,2014 ). A GAN consists of\\ntwo neural networks that contest with each other in the form of a zero-sum game, so that samples from a speciﬁc distribution can be generated.\\nFormally, the ﬁrst network Gis called the generator, which generates candidate samples. The second network Dis called the discriminator, which\\nevaluates how likely the candidate samples come from a desired distribution. Thanks to the adversarial learning objective, the generator learns to\\nmap from a latent space to a data distribution of interest, while the discriminator distinguishes candidates produced by the generator from the true\\ndata distribution (see Figure 2).\\n(Large) language model A (large) language model (LLM) refers to neural networks for modeling and generating text data that typically combine three characteristics. First,\\nthe language model uses a large-scale, sequential neural network (e.g., transformer with an attention mechanism). Second, the neural network is\\npre-trained through self-supervision in which auxiliary tasks are designed to learn a representation of natural language without risk of overﬁtting\\n(e.g., next-word prediction). Third, the pre-training makes use of large-scale datasets of text (e.g., Wikipedia, or even multi-language datasets).\\nEventually, the language model may be ﬁne-tuned by practitioners with custom datasets for speciﬁc tasks (e.g., question answering, natural\\nlanguage generation). Recently, language models have evolved into so-called LLMs, which combine billions of parameters. Prominent examples\\nof massive LLMs are BERT ( Devlin et al. ,2018 ) and GPT-3 ( Brown et al. ,2020 ) with ∼340 million and ∼175 billion parameters, respectively.\\nReinforcement learning from\\nhuman feedbackRLHF learns sequential tasks (e.g., chat dialogues) from human feedback. Different from traditional reinforcement learning, RLHF directly trains\\na so-called reward model from human feedback and then uses the model as a reward function to optimize the policy, which is optimized through\\ndata-efﬁcient and robust algorithms ( Ziegler et al. ,2019 ). RLHF is used in conversational systems such as ChatGPT ( OpenAI ,2022 ) for generating\\nchat messages, such that new answers accommodate the previous chat dialogue and ensure that the answers are in alignment with predeﬁned human\\npreferences (e.g., length, style, appropriateness).\\nPrompt learning Prompt learning is a method for LLMs that uses the knowledge stored in language models for downstream tasks ( Liu et al. ,2023 ). In general,\\nprompt learning does not require any ﬁne-tuning of the language model, which makes it efﬁcient and ﬂexible. A prompt is a speciﬁc input to a\\nlanguage model (e.g., “The movie was superb. Sentiment: “) and then the most probable output s∈ {“positive” ,“negative” }instead of the space\\nis picked. Recent advances allow for more complex data-driven prompt engineering, such as tuning prompts via reinforcement learning ( Liu et al. ,\\n2023 ).\\nseq2seq The term sequence-to-sequence (seq2seq) refers to machine learning approaches where an input sequence is mapped onto an output sequence\\n(Sutskever et al. ,2014 ). An example is machine learning-based translation between different languages. Such seq2seq approaches consist of two\\nmain components: An encoder turns each element in a sequence (e.g., each word in a text) into a corresponding hidden vector containing the\\nelement and its context. The decoder reverses the process, turning the vector into an output element (e.g., a word from the new language) while\\nconsidering the previous output to model dependencies in language. The idea of seq2seq models has been extended to allow for multi-modal\\nmappings such as text-to-image or text-to-speech mappings.\\nTransformer A transformer is a deep learning architecture ( Vaswani et al. ,2017 ) that adopts the mechanism of self-attention which differentially weights the\\nimportance of each part of the input data. Like recurrent neural networks (RNNs), transformers are designed to process sequential input data, such\\nas natural language, with applications for tasks such as translation and text summarization. However, unlike RNNs, transformers process the entire\\ninput all at once. The attention mechanism provides context for any position in the input sequence. Eventually, the output of a transformer (or an\\nRNN in general) is a document embedding, which presents a lower-dimensional representation of text (or other input) sequences where similar\\ntexts are located in closer proximity which typically beneﬁts downstream tasks as this allows to capture semantics and meaning ( Siebers et al. ,\\n2022 ).\\nVariational autoencoder A variational autoencoder (V AE) is a type of neural network that is trained to learn a low-dimensional representation of the input data by encoding it\\ninto a compressed latent variable space and then reconstructing the original data from this compressed representation. V AEs differ from traditional\\nautoencoders by using a probabilistic approach to the encoding and decoding process, which enables them to capture the underlying structure and\\nvariation in the data and generate new data samples from the learned latent space ( Kingma and Welling ,2013 ). This makes them useful for tasks\\nsuch as anomaly detection and data compression but also image and text generation.\\nZero-shot learning / few-shot\\nlearningZero-shot learning and few-shot learning refer to different paradigms of how machine learning deals with the problem of data scarcity. Zero-shot\\nlearning is when a machine is taught how to learn a task from data without ever needing to access the data itself, while few-short learning refers\\nto when there are only a few speciﬁc examples. Zero-shot learning and few-shot learning are often desirable in practice as they reduce the cost of\\nsetting up AI systems. LLMs are few-shot or zero-shot learners ( Brown et al. ,2020 ) as they just need a few samples to learn a task (e.g., predicting\\nthe sentiment of reviews), which makes LLMs highly ﬂexible as a general-purpose tool.\\nTable 1: Glossary of key concepts in generative AI.\\n2.2.2 System-Level View\\nAny system consists of a number of elements that are interconnected and interact with each other. For\\ngenerative AI systems, this comprises not only the aforementioned generative AI model but also the\\nunderlying infrastructure, user-facing components, and their modality as well as the corresponding data\\nprocessing (e.g., for prompts). An example would be the integration of deep learning models, like Codex\\n(Chen et al. ,2021 ), into a more interactive and comprehensive system, like GitHub Copilot, which\\n5a\\nzGenerator\\nDiscriminator\\nreal / fake ?\\nT raining\\nsamples\\nT raining\\nb\\nSelf-supervised\\nlearningLanguage model\\nPretrainingSupervised\\nfine-tuningConversational\\nmodelRLHF Reward model\\nHuman preference\\ndata\\nFine-tuningHuman feedback\\nFigure 2: Examples of different training procedures for generative AI models. (a) Generative adversarial\\nnetwork (GAN). (b) Reinforcement learning from human feedback (RLHF) as used in conversational\\ngenerative AI models.\\n6allows its users to code more efﬁciently. Similarly, Midjourney’s image generation system builds on an\\nundisclosed X-to-image generation model that users can interact with to generate images using Discord\\nbots. Thus, generative AI systems embed the functionality of the underlying mathematical model to\\nprovide an interface for user interaction. This step augments the model-speciﬁc capabilities, enhancing\\nits practicability and usability across real-world use cases.\\nCore concerns when embedding deep learning models in generative AI systems generally are scala-\\nbility (e.g., distributed computing resources), deployment (e.g., in various environments and for different\\ndevices), and usability (e.g., a user-friendly interface and intent recognition). As pre-trained open-source\\nalternatives to closed-source, proprietary models continue to be released, making these models available\\nto their users (be it companies or individuals) becomes increasingly important. For both open-source\\nand closed-source models, unexpected deterioration of model performance over time highlights the need\\nfor continuous model monitoring ( Chen et al. ,2023 ). Although powerful text-generating models existed\\nbefore the release of the ChatGPT system in November 2022, ChatGPT’s ease of use also for non-expert\\nusers was a core contributing factor to its explosive worldwide adoption.\\nMoreover, on the system level, multiple components of a generative AI system can be integrated or\\nconnected to other systems, external databases with domain-speciﬁc knowledge, or platforms. For exam-\\nple, common limitations in many generative AI models are that they were trained on historical data with\\nspeciﬁc cut-off date and thus do not store information beyond or that an information compression takes\\nplace because of which generative AI models may not remember everything that they saw during train-\\ning (Chiang ,2023 ). Both limitations can be mitigated by augmenting the model with functionality for\\nreal-time information retrieval, which can substantially enhance its accuracy and usefulness. Relatedly,\\nin the context of text generation, online language modeling addresses the problem of outdated models\\nby continuously training them on up-to-date data.2Thereby, such models can then be knowledgeable of\\nrecent events that their static counterparts would not be aware of due to their training cut-off dates.\\n2.2.3 Application-Level View\\nGenerative AI applications are generative AI systems situated in organizations to deliver value by solv-\\ning dedicated business problems and addressing stakeholder needs. They can be regarded as human-\\ntask-technology systems or information systems that use generative AI technology to augment human\\n2See https://github.com/huggingface/olm-datasets for a script that enables users to pull up-to-date data from the web for\\ntraining online language models, for instance, from Common Crawl and Wikipedia.\\n7capacities to accomplish speciﬁc tasks. This level of generative AI encompasses countless real-world\\nuse cases: These range from SEO content generation ( Reisenbichler et al. ,2022 ), over synthetic movie\\ngeneration ( Metz ,2023 ) and AI music generation ( Garcia ,2023 ), to natural language-based software\\ndevelopment ( Chen et al. ,2021 ).\\nGenerative AI applications will give rise to novel technology-enabled modes of work. The more\\nusers will familiarize themselves with these novel applications, the more they will trust or mistrust them\\nas well as use or disuse them. Over time, applications will likely transition from mundane tasks such as\\nwriting standard letters and getting a dinner reservation to more sensitive tasks such as soliciting medical\\nor legal advice. They will involve more consequential decisions, which may even involve moral judgment\\n(Krügel et al. ,2023 ). This ever-increasing scope and pervasiveness of generative AI applications give\\nrise to an imminent need not only to provide prescriptions and principles for trustworthy and reliable\\ndesigns, but also for scrutinizing the effects on the user to calibrate qualities such as trust appropriately.\\nThe (continued) use and adoption of such applications by end users and organizations entails a number of\\nfundamental socio-technical considerations to descry innovation potential and affordances of generative\\nAI artifacts.\\n2.3 A Socio-Technical View on Generative AI\\nAs technology advances, the deﬁnition and extent of what constitutes AI are continuously reﬁned, while\\nthe reference point of human intelligence stays comparatively constant ( Berente et al. ,2021 ). With\\ngenerative AI, we are approaching a further point of reﬁnement . In the past, the capability of AI was\\nmostly understood to be analytic, suitable for decision-making tasks. Now, AI gains the capability to\\nperform generative tasks, suitable for content creation. While the procedure of content creation to some\\nrespect can still be considered analytic as it is inherently probabilistic, its results can be creative or even\\nartistic as generative AI combines elements in novel ways. Further, IT artifacts were considered passive\\nas they were used directly by humans. With the advent of agentic IT artifacts ( Baird and Maruping ,2021 )\\npowered by LLMs ( Park et al. ,2023 ), this human agency primacy assumption needs to be revisited and\\nimpacts how we devise the relation between human and AI based on their potency. Eventually, this\\nmay require AI capability models to structure, explain, guide, and constrain the different abilities of AI\\nsystems and their uses as AI applications.\\nFocusing on the interaction between humans and AI, so far, for analytic AI, the concept of delegation\\n8has been discussed to establish a hierarchy for decision-making ( Baird and Maruping ,2021 ). With\\ngenerative AI, a human uses prompts to engage with an AI system to create content, and the AI then\\ninterprets the humans’ intentions and provides feedback to presuppose further prompts. At ﬁrst glance,\\nthis seems to follow a delegation pattern as well. Yet, the subsequent process does not, as the output of\\nthe AI can be suggestive to the other and will inform their further involvement directly or subconsciously.\\nThus, the process of creation rather follows a co-creation pattern, that is, the practice of collaborating\\nin different roles to align and offer diverse insights to guide a design process ( Ramaswamy and Ozcan ,\\n2018 ). Using the lens of agentic AI artifacts, initiation is not limited to humans.\\nThe abovementioned interactions also impact our current understanding of hybrid intelligence as the\\nintegration of humans and AI, leveraging the unique strengths of both. Hybrid intelligence argues to\\naddress the limitations of each intelligence type by combining human intuition, creativity, and empathy\\nwith the computational power, accuracy, and scalability of AI systems to achieve enhanced decision-\\nmaking and problem-solving capabilities ( Dellermann et al. ,2019 ). With generative AI and the AI’s\\ncapability to co-create, the understanding of what constitutes this collective intelligence begins to shift.\\nHence, novel human-AI interaction models and patterns may become necessary to explain and guide the\\nbehavior of humans and AI systems to enable effective and efﬁcient use in AI applications on the one\\nhand and, on the other hand, to ensure envelopment of AI agency and reach ( Asatiani et al. ,2021 ).\\nOn a theoretical level, this shift in human-computer or rather human-AI interaction fuels another\\nimportant observation: The theory of mind is an established theoretical lens in psychology to describe\\nthe cognitive ability of individuals to understand and predict the mental states, emotions, and intentions\\nof others ( Baron-Cohen ,1997 ;Carlson et al. ,2013 ;Gray et al. ,2007 ). This skill is crucial for social\\ninteractions, as it facilitates empathy and allows for effective communication. Moreover, conferring a\\nmind to an AI system can substantially drive usage intensity ( Hartmann et al. ,2023a ). The development\\nof a theory of mind in humans is unconscious and evolves throughout an individual’s life. The more\\nnatural AI systems become in terms of their interface and output, the more a theory of mind for human-\\ncomputer interactions becomes necessary. Research is already investigating how AI systems can become\\ntheory-of-mind-aware to better understand their human counterpart ( Çelikok et al. ,2019 ;Rabinowitz\\net al.,2018 ). However, current AI systems hardly offer any cues for interactions. Thus, humans are rather\\nvoid of a theory to explain their understanding of intelligent behavior by AI systems, which becomes\\neven more important in a co-creation environment that does not follow a task delegation pattern. A\\n9theory of the artiﬁcial mind that explains how individuals perceive and assume the states and rationale\\nof AI systems to better collaborate with them may alleviate some of these concerns.\\n3 Limitations of Current Generative AI\\nIn the following, we discuss four salient boundaries of generative AI that, we argue, are important limi-\\ntations in real-world applications. The following limitations are of technical nature in that they refer to\\nhow current generative AI models make inferences, and, hence, the limitations arise at the model level.\\nBecause of this, it is likely that limitations will persist in the long run, with system- and application-level\\nimplications.\\nIncorrect outputs. Generative AI models may produce output with errors. This is owed to the\\nunderlying nature of machine learning models relying on probabilistic algorithms for making inferences.\\nFor example, generative AI models generate the most probable response to a prompt, not necessarily\\nthe correct response. As such, challenges arise as, by now, outputs are indistinguishable from authentic\\ncontent and may present misinformation or deceive users ( Spitale et al. ,2023 ). In LLMs, this problem in\\nemergent behavior is called hallucination ( Ji et al. ,2023 ), which refers to mistakes in the generated text\\nthat are semantically or syntactically plausible but are actually nonsensical or incorrect. In other words,\\nthe generative AI model produces content that is not based on any facts or evidence, but rather on its own\\nassumptions or biases. Moreover, the output of generative AI, especially that of LLMs, is typically not\\neasily veriﬁable.\\nThe correctness of generative AI models is highly dependent on the quality of training data and the\\naccording learning process. Generative AI systems and applications can implement correctness checks\\nto inhibit certain outputs. Yet, due to the black-box nature of state-of-the-art AI models ( Rai,2020 ),\\nthe usage of such systems critically hinges on users’ trust in reliable outputs. The closed source of\\ncommercial off-the-shelf generative AI systems aggravates this fact and prohibits further tuning and re-\\ntraining of the models. One solution for addressing the downstream implications of incorrect outputs is\\nto use generative AI to produce explanations or references, which can then be veriﬁed by users. However,\\nsuch explanations are again probabilistic and thus subject to errors; nevertheless, they may help users in\\ntheir judgment and decision-making when to accept outputs of generative AI and when not.\\nBias and fairness. Societal biases permeate everyday human-generated content ( Eskreis-Winkler\\nand Fishbach ,2022 ). The unbiasedness of vanilla generative AI is very much dependent on the quality\\n10of training data and the alignment process. Training deep learning models on biased data can amplify\\nhuman biases, replicate toxic language, or perpetuate stereotypes of gender, sexual orientation, political\\nleaning, or religion (e.g., Caliskan et al. ,2017 ;Hartmann et al. ,2023b ). Recent studies expose the\\nharmful biases embedded in multimodal generative AI models such as CLIP (contrastive language-image\\npre-training; Wolfe et al. (2022 )) and the CLIP-ﬁltered LAION dataset ( Birhane et al. ,2021 ), which are\\ncore components of generative AI models (e.g., Dall-E 2 or Stable Diffusion). Human biases can also\\ncreep into the models in other stages of the model engineering process. For instruction-based language\\nmodels, the RLHF process is an additional source of bias ( OpenAI ,2023b ). Careful coding guidelines\\nand quality checks can help address these risks.\\nAddressing bias and thus fairness in AI receives increasing attention in the academic literature ( De-\\nArteaga et al. ,2022 ;Dolata et al. ,2022 ;Ferrara ,2023 ;Feuerriegel et al. ,2020 ;Schramowski et al. ,2022 ;\\nvon Zahn et al. ,2022 ), but remains an open and ongoing research question. For example, the developers\\nof Stable Diffusion ﬂag “probing and understanding the limitations and biases of generative models” as\\nan important research area ( Rombach et al. ,2022 ). Some scholars even attest to models certain moral\\nself-correcting capabilities ( Ganguli et al. ,2023 ), which may attenuate concerns of embedded biases and\\nresult in more fairness. In addition, on the system and application level, mitigation mechanisms can be\\nimplemented to address biases embedded in the deep learning models and create more diverse outputs\\n(e.g., updating the prompts “under the hood” as done by Dall-E 2 to increase the demographic diversity\\nof the outputs). Yet, more research is needed to get closer to the notion of fair AI.\\nCopyright violation. Generative AI models, systems, and applications may cause a violation of\\ncopyright laws because they can produce outputs that resemble or even copy existing works without\\npermission or compensation to the original creators ( Smits and Borghuis ,2022 ). Here, two potential\\ninfringement risks are common. On the one hand, generative AI may make illegal copies of a work, thus\\nviolating the reproduction right of creators. Among others, this may happen when a generative AI was\\ntrained on original content that is protected by copyright but where the generative AI produces copies.\\nHence, a typical implication is that the training data for building generative AI systems must be free of\\ncopyrights. Crucially, copyright violation may nevertheless still happen even when the generative AI has\\nnever seen a copyrighted work before, such as, for example, when it simply produces a trademarked logo\\nsimilar to that of Adidas but without having never seen that logo before. On the other hand, generative\\nAI may prepare derivative works, thus violating the transformation right of creators. To this end, legal\\n11questions arise around the balance of originality and creativity in generative AI systems. Along these\\nlines, legal questions also arise around who holds the intellectual property for works (including patents)\\nproduced by a generative AI.\\nEnvironmental concerns. Lastly, there are substantial environmental concerns from developing\\nand using generative AI systems due to the fact that such systems are typically built around large-scale\\nneural networks, and, therefore, their development and operation consume large amounts of electricity\\nwith immense negative carbon footprint ( Schwartz et al. ,2020 ). For example, the carbon emission for\\ntraining a generative AI model such as GPT-3 was estimated to have produced the equivalent of 552 t CO 2\\nand thus amounts to the annual CO 2emissions of several dozens of households ( Khan ,2021 ). Owing to\\nthis, there are ongoing efforts in AI research to make the development and deployment of AI algorithms\\nmore carbon-friendly, through more efﬁcient training algorithms, through compressing the size of neural\\nnetwork architectures, and through optimized hardware ( Schwartz et al. ,2020 ).\\n4 Implications and Future Directions for the BISE Community\\nIn this section, we draw a number of implications and future research directions which, on the one\\nhand, are of direct relevance to the BISE community as an application-oriented, socio-technical research\\ndiscipline and, on the other hand, offer numerous research opportunities, especially for BISE researchers\\ndue to their interdisciplinary background. We organize our considerations according to the individual\\ndepartments of the BISE journal (see Table 2for an overview of exemplary research questions).\\n4.1 Business Process Management\\nGenerative AI will have a strong impact on the ﬁeld of Business Process Management (BPM) as it can\\nassist in automating routine tasks, improving customer and employee satisfaction, and revealing process\\ninnovation opportunities ( Beverungen et al. ,2021 ), especially in creative processes ( Haase and Hanel ,\\n2023 ). Concrete implications and research directions can be connected to various phases of the BPM\\nlifecycle model ( Vidgof et al. ,2023 ). For example, in the context of process discovery, generative AI\\nmodels could be used to generate process descriptions, which can help businesses identify and under-\\nstand the different stages of a process ( Kecht et al. ,2023 ). From the perspective of business process\\nimprovement, generative process models could be used for idea generation and to support innovative\\nprocess (re-)design initiatives ( van Dun et al. ,2023 ). In this regard, there is great potential for generative\\n12BISE department Research questions (examples)\\nBusiness process management •How can generative AI assist in automating routine tasks?\\n•How can generative AI reveal process innovation opportunities\\nand support process (re-)design initiatives?\\nDecision analytics and data science •How can generative AI models be effectively ﬁne-tuned for\\ndomain-speciﬁc applications?\\n•How can the reliability of generative AI systems be improved?\\nDigital business management and digi-\\ntal leadership•How can generative AI support managerial tasks such as re-\\nsource allocation?\\n•How will the digital work of employees change with smart as-\\nsistants powered by generative AI?\\nEconomics of information systems •What are the welfare implications of generative AI?\\n•Which jobs and tasks are affected most by generative AI?\\nEnterprise modeling and enterprise en-\\ngineering•How can generative AI be used to support the construction and\\nmaintenance of enterprise models?\\n•How can generative AI support in enterprise applications (e.g.,\\nCRM, BI, etc.)?\\nHuman computer interaction and social\\ncomputing•How should generative AI systems be designed to foster trust?\\n•What countermeasures are effective to prevent users from falling\\nfor AI-generated disinformation?\\n•To what extent can generative AI replace or augment crowd-\\nsourcing tasks?\\n•How can generative AI assist in education?\\nInformation systems engineering and\\ntechnology•What are effective design principles for developing generative\\nAI systems?\\n•How can generative AI support design science projects to foster\\ncreativity in the development of new IT artifacts?\\nTable 2: Examples of research questions for future BISE research on generative AI.\\n13AI to contribute to both exploitative as well as explorative BPM design strategies ( Grisold et al. ,2022 ).\\nIn addition, natural language processing tasks related to BPM such as process extraction from text could\\nbeneﬁt from generative AI without further ﬁne-tuning using prompt engineering ( Busch et al. ,2023 ).\\nLikewise, other phases can beneﬁt owing to generative AI’s ability to learn complex and non-linear re-\\nlationships in dynamic business processes that can be used for implementation as well as in simulation\\nand predictive process monitoring among other things.\\nIn the short term, robotic process automation ( Herm et al. ,2021 ;van der Aalst et al. ,2018 ) will\\nbeneﬁt as formerly handcrafted processing rules can not only be replaced, but entirely new types of au-\\ntomation can be enabled by retroﬁtting and thus intelligentizing legacy software. In the long run, we also\\nsee a large potential to support the phase of business process execution in traditional BPM. Speciﬁcally,\\nwe anticipate the development of a new generation of process guidance systems. While traditional system\\ndesigns are based on static and manually-crafted knowledge bases ( Morana et al. ,2019 ), more dynamic\\nand adaptive systems are feasible on the basis of large enterprise-wide trained language models. Such\\nsystems could improve knowledge retrieval tasks from a wide variety of heterogeneous sources, including\\nmanuals, handbooks, e-mails, wikis, job descriptions, etc. This opens up new avenues of research into\\nhow unstructured and distributed organizational knowledge can be incorporated into intelligent process\\nguidance systems.\\n4.2 Decision Analytics and Data Science\\nDespite the huge progress in recent years, several analytical and technical questions around the devel-\\nopment of generative AI have yet to be solved. One open question relates to how generative AI can be\\neffectively customized for domain-speciﬁc applications and thus improve performance through higher\\ndegrees of contextualization. For example, novel and scalable techniques are needed to customize con-\\nversational agents based on generative AI for applications in medicine or ﬁnance. This will be crucial\\nin practice to solve speciﬁc BISE-related tasks where customization may bring additional performance\\ngains. Novel techniques for customization must be designed in a way that ensures the safety of propri-\\netary data and prevents the data from being disclosed. Moreover, new frameworks are needed for prompt\\nengineering that are designed from a user-centered lens and thus promote interpretability and usability.\\nAnother important research direction is to improve the reliability of generative AI systems. For\\nexample, algorithmic solutions are needed on how generative AI can detect and mitigate hallucination.\\n14In addition to algorithmic solutions, more effort is also needed to develop user-centered solutions, that is,\\nhow users can reduce the risk of falling for incorrect outcomes, for example, by developing better ways\\nhow outputs can be veriﬁed (e.g., by offering additional explanations or references).\\nFinally, questions arise about how generative AI can natively support decision analytics and data\\nscience projects by closing the gap between modeling experts and domain users ( Zschech et al. ,2020 ).\\nFor instance, it is commonly known that many AI models used in business analytics are difﬁcult to un-\\nderstand by non-experts (cf. Senoner et al. ,2022 ). As a remedy, generative AI could be used to generate\\ndescriptions that explain the logic of business analytics models and thus make the decision logic more\\nintelligible. One promising direction could be, for example, to use generative AI for translating post hoc\\nexplanations derived from approaches like SHAP or LIME into more intuitive textual descriptions or gen-\\nerate user-friendly descriptions of models that are intrinsically interpretable ( Slack et al. ,2023 ;Zilker\\net al.,2023 ).\\n4.3 Digital Business Management and Digital Leadership\\nGenerative AI has great potential to contribute to different types of value creation mechanisms, includ-\\ning knowledge creation, task augmentation, and autonomous agency. However, this also requires the\\nnecessary organizational capabilities and conditions, where further research is needed to examine these\\ningredients more closely for the context of generative AI to steer the technological possibilities in a\\nsuccessful direction ( Shollo et al. ,2022 ).\\nThat is, generative AI will lead to the development of new business ideas, unseen product and ser-\\nvice innovations, and ultimately to the emergence of completely new business models. At the same time,\\nit will also have a strong impact on intra-organizational aspects, such as work patterns, organizational\\nstructures, leadership models, and management practices. In this regard, we see that AI-based assistant\\nsystems previously centered around desktop automation taking over more and more routine tasks such as\\nevent management, resource allocation, and social media account management to free up even more hu-\\nman capacity ( Maedche et al. ,2019 ). Further, in algorithmic management ( Benlian et al. ,2022 ;Cameron\\net al. ,2023 ), it should be examined how existing theories and frameworks need to be contextualized or\\nfundamentally extended in light of the increasingly powerful capabilities of generative AI.\\nHowever, there are not only implications at the management level. The future of work is very likely to\\nchange at all levels of an organization ( Feuerriegel et al. ,2022 ). Due to the multi-modality of generative\\n15AI models, it is conceivable that employees will work increasingly via smart, speech-based interfaces,\\nwhereby the formulation of prompts and the evaluation of their results could become a key activity.\\nAgainst this background, it is worth investigating which new competencies are required to handle this\\nemerging technology (cf. Debortoli et al. ,2014 ) and which entirely new job proﬁles, such as prompt\\nengineers, may evolve in the near future ( Strobelt et al. ,2023 ).\\nGenerative AI is also expected to fundamentally reform the way organizations manage, maintain, and\\nshare knowledge. Referring to the sketched vision of a new process guidance system in Section 4.1, we\\nanticipate a number of new opportunities for digital knowledge management, among others automated\\nknowledge discovery based on large amounts of unstructured distributed data (e.g., identiﬁcation of new\\nproduct combinations), improved knowledge sharing by automating the process of creating, summariz-\\ning, and disseminating content (e.g., automated creation of wikis and FAQs in different languages), and\\npersonalized knowledge delivery to individual employees based on their speciﬁc needs and preferences\\n(e.g., recommendations for speciﬁc training material).\\n4.4 Economics of Information Systems\\nGenerative AI will have signiﬁcant economic implications across various industries and markets. Gen-\\nerative AI can increase efﬁciency and productivity by automating many tasks that were previously per-\\nformed by humans, such as content creation, customer service, code generation, etc. This can reduce\\ncosts and open up new opportunities for growth and innovation ( Eloundou et al. ,2023 ). For example,\\nAI-based translation between different languages is responsible for signiﬁcant economic gains ( Bryn-\\njolfsson et al. ,2019 ). The BISE community can contribute by providing quantiﬁcation through rigorous\\ncausal evidence. Given the velocity of AI research, it may be necessary to take a more abstract problem\\nview instead of a concrete tool view. For example, BISE research could run ﬁeld experiments to compare\\nprogrammers with and without AI support and thereby assess whether generative AI systems for coding\\ncan improve the speed and quality of code development. Similarly, researchers could test whether gen-\\nerative AI will make artists more creative as they can more easily create new content. A similar pattern\\nwas previously observed for AlphaGo, which has led humans to become better players in the board game\\nGo (Shin et al. ,2023 ).\\nGenerative AI is likely to transform the industry as a whole. This may hold true in the case of\\nplatforms that make user-generated content available (e.g., shutterstock.com, pixabay.com, stackover-\\n16ﬂow.com), which may be replaced by generative AI systems. Here, further research questions arise as\\nto whether the use of generative AI can lead to a competitive advantage and how generative AI changes\\ncompetition. For example, what are the economic implications if generative AI is developed as open-\\nsource vs. in closed-source systems? In this regard, a salient success factor for the development of\\nconversational agents based on generative AI (e.g., ChatGPT) are data from user interactions through\\ndialogues and feedback on whether the dialog was helpful. Hence, the value of such interaction data is\\npoorly understood and what it means if such data are only available to a few Big Tech companies.\\nThe digital transformation from generative AI also poses challenges and opportunities for economic\\npolicy. It may affect future work patterns and, indirectly, worker capability via restructured learning\\nmechanisms. It may also affect content sharing and distribution and, hence, have non-trivial implications\\non the exploitation and protection of intellectual properties. On top of that, a growing concentration of\\npower over AI innovation in the hands of a few companies may result in a monopoly of AI capabilities\\nand hamper future innovation, fair competition, scientiﬁc progress, and thus welfare and human develop-\\nment at large. All of these future impacts are important to understand and provide meaningful directions\\nfor shaping economic policy.\\n4.5 Enterprise Modeling and Enterprise Engineering\\nEnterprise models are important artifacts for capturing insights into the core components and structures\\nof an organization, including business processes, resources, information ﬂows, and IT systems ( Vernadat ,\\n2020 ). A major drawback of traditional enterprise models is that they are static and may not provide the\\nlevel of abstraction that is required by the end user. Likewise, their construction and maintenance are\\ntime-consuming and expensive and require manual effort and human expertise ( Silva et al. ,2021 ). With\\ngenerative AI, we see a large potential that many of these limitations can be addressed by generative\\nAI as assistive technology ( Sandkuhl et al. ,2018 ), for example by automatically creating and updating\\nenterprise models at different levels of abstraction or generating multi-modal representations.\\nFirst empirical results suggest that generative AI is able to generate useful conceptual models based\\non textual problem descriptions. Fill et al. (2023 ) show that ER, BPMN, UML, and Heraklit models\\ncan not only be generated with very high to perfect accuracy from textual descriptions, but they also\\nexplored the interpretation of existing models and received good results. In the near future, we expect\\nmore research that deals with the development, evaluation, and application of more advanced approaches.\\n17Speciﬁcally, we expect that learned representations of enterprise models can be transformed into more\\napplication-speciﬁc formats and can either be enriched with further details or reduced to the essential\\ncontent.\\nAgainst this background, the concept of “digital twins”, virtual representations of enterprise assets,\\nmay experience new accentuation and extensions ( Dietz and Pernul ,2020 ). Especially, in the public\\nsector, where most organizational assets are non-tangible in the form of deﬁned services, speciﬁed pro-\\ncedures, legal texts, manuals, and organizational charts, generative AI can play a crucial role in digitally\\nmirroring and managing such assets along their lifecycles. Similar beneﬁts could be explored with phys-\\nical assets in Industry 4.0 environments ( Lasi et al. ,2014 ).\\nIn enterprise engineering, the role of generative AI systems in existing as well as newly emerging IT\\nlandscapes to support the business goals and strategies of an organization gives rise to numerous oppor-\\ntunities (e.g., in ofﬁce solutions, customer relationship management and business analytics applications,\\nknowledge management systems, etc.). Generative AI systems have the potential to evolve into core\\nenterprise applications that can either be hosted on-premise or rented in the cloud. Unsanctioned use\\nbears the risk that third-party applications will be used for job-related tasks without explicit approval or\\neven knowledge of the organization. This phenomenon is commonly known as shadow IT and theories\\nand frameworks have been proposed to explain this phenomenon, as well as recommending actions and\\npolicies to mitigate associated risks (cf. Haag and Eckhardt ,2017 ;Klotz et al. ,2022 ). In the light of\\ngenerative AI, however, such approaches have to be revisited for their applicability and effectiveness\\nand, if necessary, need to be extended. Nevertheless, this situation also offers the potential to explore and\\ndesign new approaches for more effective API management (e.g., including novel app store solutions,\\nprivacy and security mechanisms, service level deﬁnitions, pricing, and licensing models) so that gener-\\native AI solutions can be smoothly integrated into existing enterprise IT infrastructures without risking\\nany unauthorized use and conﬁdentiality breaches.\\n4.6 Human Computer Interaction and Social Computing\\nSalient behavioral questions related to the interactions between humans and generative AI systems are\\nstill unanswered. Examples are related to the perception, acceptance, adoption, and trust of systems\\nusing generative AI. A study found that news was believed less if generated by generative AI instead of\\nhumans ( Longoni et al. ,2022 ) and another found that there is a replicant effect ( Jakesch et al. ,2019 ).\\n18Such behavior is likely to be context-speciﬁc and will vary by other antecedents highlighting the need\\nfor a principled theoretical foundation to build successful generative AI systems. The BISE community\\nis well positioned to develop rigorous design recommendations.\\nFurther, generative AI is a key enabler for developing high-quality interfaces for information systems\\nbased on natural language that promote usability and accessibility. For example, such interfaces will not\\nonly make interactions more intuitive but will also facilitate people with disabilities. Generative AI is\\nlikely to increase the “degree of intelligence” of user assistance systems. However, the design of effective\\ninteractions must also be considered when increasing the degree of intelligence ( Maedche et al. ,2016 ).\\nSimilarly, generative AI will undoubtedly have an impact on (computer-mediated) communication and\\ncollaboration, such as within companies. For example, generative AI can create optimized content for so-\\ncial media, emails, and reports. It can also help to improve the onboarding of new employees by creating\\npersonalized and interactive training materials. It can also enhance collaboration within teams by pro-\\nviding creative and intelligence conservation agents that suggest, summarize, and synthesize information\\nbased on the context of the team (e.g., automated meeting notes).\\nSeveral applications and research opportunities are related to the use of generative AI in marketing\\nand, especially, e-commerce. It is expected that generative AI can automate the creation of personalized\\nmarketing content, for instance, different sales slogans for introverts vs. extroverts ( Matz et al. ,2017 )\\nor other personality traits as personalized marketing content is more effective than a one-content-ﬁts-all\\napproach ( Matz et al. ,2023 ). Generative AI may automate various tasks in marketing and media where\\ncontent generation is needed (e.g., writing news stories, summarizing web pages for mobile devices,\\ncreating thumbnail images for news stories, translating written news to audio for blind people and Braille-\\nsupported formats for deaf people) that may be studied in future research. Moreover, generative AI\\nmay be used in recommender systems to boost the effectiveness of information dissemination through\\npersonalization as content can be tailored better to the abilities of the recipient.\\nThe education sector is another example that will need to reinvent in some parts following the avail-\\nability of conversational agents ( Gimpel et al. ,2023 ;Kasneci et al. ,2023 ). At ﬁrst glance, generative AI\\nseems to constitute an unauthorized aid that jeopardizes student grading so far relying on written exam-\\ninations and term papers. However, over time, examinations will adapt, and generative AI will enable\\nthe development of comprehensive digital teaching assistants as well as the creation of supplemental\\nteaching material such as teaching cases and recap questions. Further, the educator’s community will\\n19need to develop novel guidelines and governance frameworks that educate learners to rely appropriately\\non generative AI systems, how to verify model outputs, and to engineer prompts rather than the output\\nitself.\\nIn addition, generative AI, speciﬁcally, LLMs, can not only be used to spot harmful content on social\\nmedia (e.g., Maarouf et al. ,2023 ), but it can also create realistic disinformation (e.g., fake news, pro-\\npaganda) that is hard to detect by humans ( Jakesch et al. ,2023 ;Kreps et al. ,2022 ). Notwithstanding,\\nAI-generated disinformation has previously evolved as so-called deepfakes ( Mirsky and Lee ,2021 ), but\\nrecent advances in generative AI reduce the cost of creating such disinformation and allow for unprece-\\ndented personalization. For example, generative AI can automatically adapt the tone and narrative of\\nmisinformation to speciﬁc audiences that identify as extroverts or introverts, left- or right-wing parti-\\nsans, or people with particular religious beliefs.\\nLastly, generative AI can facilitate – or even replace – traditional crowdsourcing where annotations\\nor other knowledge tasks are handled by a larger pool of crowd workers, for example in social me-\\ndia content annotation ( Gilardi et al. ,2023 ) or market research on willingness-to-pay for services and\\nproducts ( Brand et al. ,2023 ). In general, we expect that generative AI will automate many other tasks\\nbeing a zero-shot / few-shot learner. However, this may also unfold negative implications: Users may\\ncontribute less to question-answering forums such as stackoverﬂow.com, which thus may reduce human-\\nbased knowledge creation impairing the future performance of AI-based question-answering systems\\nthat rely upon human question-answering content for training. In a similar vein, the widespread avail-\\nability of generative AI systems may also propel research around virtual assistants. Previously, research\\nmade use of “Wizard-of-Oz” experiments ( Diederich et al. ,2020 ), while future research may build upon\\ngenerative AI systems instead.\\nCrucially, automated content generation using generative AI is a new phenomenon, but automation\\nin general and how people are affected by automated systems has been studied by scholars for decades.\\nThus, existing theories on the interplay of humans with automated systems may be contextualized to\\ngenerative AI systems.\\n4.7 Information Systems Engineering and Technology\\nGenerative AI offers many engineering- and technology-oriented research opportunities for the Infor-\\nmation Systems community as a design-oriented discipline. This includes developing and evaluating\\n20design principles for generative AI systems and applications to extend the limiting boundaries of this\\ntechnology (cf. Section 3). As such, design principles can focus on how generative AI systems can be\\nmade explainable to enable interpretability, understanding, and trust; how they can be designed reliable\\nto avoid discrimination effects or privacy issues; and how they can be built more energy efﬁcient to\\npromote environmental sustainability (cf. Schoormann et al. ,2023b ). While a lot of research is already\\nbeing conducted in technology-oriented disciplines such as computer science, the BISE community can\\nadd its strength by looking at design aspects through a socio-technical lens, involving individuals, teams,\\norganizations, and societal groups in design activities, and thereby driving the ﬁeld forward with new\\ninsights from a human-machine perspective ( Maedche et al. ,2019 ).\\nFurther, we see great potential that generative AI can be leveraged to improve current practices in\\ndesign science research projects when constructing novel IT artifacts (see Hevner et al. ,2019 ). Here,\\none of the biggest potentials could lie in the support of knowledge retrieval tasks. Currently, design\\nknowledge in the form of design requirements, design principles, and design features is often only avail-\\nable in encapsulated written papers or implicitly embedded in instantiated artifacts. Generative AI has\\nthe potential to extract such design knowledge that is spread over a broad body of interdisciplinary re-\\nsearch and make it available in a collective form for scholars and practitioners. This could also overcome\\nthe limitation that design knowledge is currently rarely reused, which hampers the fundamental idea of\\nknowledge accumulation in design science research ( Schoormann et al. ,2021 ).\\nBesides engineering actual systems and applications, the BISE community should also investigate\\nhow generative AI can be used to support creativity-based tasks when initiating new design projects. In\\nthis regard, a promising direction could be to incorporate generative AI in design thinking and similar\\nmethodologies to combine human creativity with computational creativity ( Hawlitschek ,2023 ). This\\nmay support different phases and steps of innovation projects, such as idea generation, user needs elici-\\ntation, prototyping, design evaluation, and design automation, in which different types of generative AI\\nmodels and systems could be used and combined with each other to form applications for creative indus-\\ntries (e.g., generated user stories with textual descriptions, visual mock-ups for user interfaces, and quick\\nsoftware prototypes for proofs-of-concept). If generative AI is used to co-create innovative outcomes,\\nit may also enable better reﬂection of the different design activities to ensure the necessary learning\\n(Schoormann et al. ,2023a ).\\n215 Conclusion\\nGenerative AI is a branch of AI that can create new content such as texts, images, or audio that increas-\\ningly often cannot be distinguished anymore from human craftsmanship. For this reason, generative AI\\nhas the potential to transform domains and industries that rely on creativity, innovation, and knowledge\\nprocessing. In particular, it enables new applications that were previously impossible or impractical\\nfor automation, such as realistic virtual assistants, personalized education and service, and digital art.\\nAs such, generative AI has substantial implications for BISE practitioners and scholars as an interdisci-\\nplinary research community. In our Catchword article, we offered a conceptualization of the principles of\\ngenerative AI along a model-, system-, and application-level view as well as a social-technical view and\\ndescribed limitations of current generative AI. Ultimately, we provided an impactful research agenda for\\nthe BISE community and thereby highlight the manifold affordances that generative AI offers through\\nthe lens of the BISE discipline.\\nAcknowledgments\\nDuring the preparation of this Catchword, we contacted all current department editors at BISE to actively\\nseek their feedback on our suggested directions. We gratefully acknowledge their support.\\nReferences\\nAgostinelli, A., Denk, T. I., Borsos, Z., Engel, J., Verzetti, M., Caillon, A., Huang, Q., Jansen,\\nA., Roberts, A., Tagliasacchi, M., et al. (2023). MusicLM: Generating music from text.\\narXiv:2301.11325 .\\nAsatiani, A., Malo, P., Nagbøl, P. R., Penttinen, E., Rinta-Kahila, T., and Salovaara, A. (2021). So-\\nciotechnical envelopment of artiﬁcial intelligence: An approach to organizational deployment of\\ninscrutable artiﬁcial intelligence systems. Journal of the Association for Information Systems ,\\n22(2):Article 8.\\nBaird, A. and Maruping, L. M. (2021). The next generation of research on IS use: A theoretical frame-\\nwork of delegation to and from agentic IS artifacts. MIS Quarterly , 45(1):315–341.\\nBaron-Cohen, S. (1997). Mindblindness: An Essay on Autism and Theory of Mind . MIT Press, Cam-\\nbridge, MA.\\nBenlian, A., Wiener, M., Cram, W. A., Krasnova, H., Maedche, A., Möhlmann, M., Recker, J., and\\nRemus, U. (2022). Algorithmic management. Business & Information Systems Engineering ,\\n64(6):825–839.\\nBerente, N., Gu, B., Recker, J., and Santhanam, R. (2021). Special issue editor’s comments: Managing\\nartiﬁcial intelligence. MIS Quarterly , 45(3):1433–1450.\\nBeverungen, D., Buijs, J. C. A. M., Becker, J., Di Ciccio, C., van der Aalst, W. M. P., Bartelheimer, C.,\\nvom Brocke, J., Comuzzi, M., Kraume, K., Leopold, H., Matzner, M., Mendling, J., Ogonek, N.,\\nPost, T., Resinas, M., Revoredo, K., del Río-Ortega, A., La Rosa, M., Santoro, F. M., Solti, A.,\\nSong, M., Stein, A., Stierle, M., and Wolf, V. (2021). Seven paradoxes of business process manage-\\nment in a hyper-connected world. Business & Information Systems Engineering , 63(2):145–156.\\n22Birhane, A., Prabhu, V. U., and Kahembwe, E. (2021). Multimodal datasets: Misogyny, pornography,\\nand malignant stereotypes. arXiv:2110.01963 .\\nBishop, C. (2006). Pattern Recognition and Machine Learning . Springer, New York, NY.\\nBommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg,\\nJ., Bosselut, A., Brunskill, E., Brynjolfsson, E., Buch, S., Card, D., Castellon, R., Chatterji, N. S.,\\nChen, A. S., Creel, K. A., Davis, J., Demszky, D., Donahue, C., Doumbouya, M., Durmus, E.,\\nErmon, S., Etchemendy, J., Ethayarajh, K., Fei-Fei, L., Finn, C., Gale, T., Gillespie, L. E., Goel,\\nK., Goodman, N. D., Grossman, S., Guha, N., Hashimoto, T., Henderson, P., Hewitt, J., Ho,\\nD. E., Hong, J., Hsu, K., Huang, J., Icard, T. F., Jain, S., Jurafsky, D., Kalluri, P., Karamcheti,\\nS., Keeling, G., Khani, F., Khattab, O., Koh, P. W., Krass, M. S., Krishna, R., Kuditipudi, R.,\\nKumar, A., Ladhak, F., Lee, M., Lee, T., Leskovec, J., Levent, I., Li, X. L., Li, X., Ma, T.,\\nMalik, A., Manning, C. D., Mirchandani, S. P., Mitchell, E., Munyikwa, Z., Nair, S., Narayan, A.,\\nNarayanan, D., Newman, B., Nie, A., Niebles, J. C., Nilforoshan, H., Nyarko, J. F., Ogut, G., Orr,\\nL., Papadimitriou, I., Park, J. S., Piech, C., Portelance, E., Potts, C., Raghunathan, A., Reich, R.,\\nRen, H., Rong, F., Roohani, Y. H., Ruiz, C., Ryan, J., R’e, C., Sadigh, D., Sagawa, S., Santhanam,\\nK., Shih, A., Srinivasan, K. P., Tamkin, A., Taori, R., Thomas, A. W., Tramèr, F., Wang, R. E.,\\nWang, W., Wu, B., Wu, J., Wu, Y., Xie, S. M., Yasunaga, M., You, J., Zaharia, M. A., Zhang, M.,\\nZhang, T., Zhang, X., Zhang, Y., Zheng, L., Zhou, K., and Liang, P. (2021). On the opportunities\\nand risks of foundation models. arXiv:2108.07258 .\\nBrand, J., Israeli, A., and Ngwe, D. (2023). Using GPT for market research. SSRN 4395751 .\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P.,\\nSastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Advances in Neural\\nInformation Processing Systems , 33:1877–1901.\\nBrynjolfsson, E., Hui, X., and Liu, M. (2019). Does machine translation affect international trade?\\nEvidence from a large digital platform. Management Science , 65(12):5449–5460.\\nBurger, B., Kanbach, D. K., Kraus, S., Breier, M., and Corvello, V. (2023). On the use of AI-based tools\\nlike ChatGPT to support management research. European Journal of Innovation Management ,\\n26(7):233–241.\\nBusch, K., Rochlitzer1, A., Sola, D., and Leopold, H. (2023). Just tell me: Prompt engineering in\\nbusiness process management. arXiv:2304.07183 .\\nCaliskan, A., Bryson, J. J., and Narayanan, A. (2017). Semantics derived automatically from language\\ncorpora contain human-like biases. Science , 356(6334):183–186.\\nCameron, L., Lamers, L., Leicht-Deobald, U., Lutz, C., Meijerink, J., and Möhlmann, M. (2023). Algo-\\nrithmic management: Its implications for information systems research. Communications of the\\nAssociation for Information Systems , 52(1):518–537.\\nCarlson, S. M., Koenig, M. A., and Harms, M. B. (2013). Theory of mind. WIREs Cognitive Science ,\\n4:391–402.\\nÇelikok, M. M., Peltola, T., Daee, P., and Kaski, S. (2019). Interactive AI with a theory of mind. In\\nACM CHI 2019 Workshop: Computational Modeling in Human-Computer Interaction , volume 80,\\npages 4215–4224.\\nChen, L., Zaharia, M., and Zou, J. (2023). How is chatgpt’s behavior changing over time?\\narXiv:2307.09009 .\\nChen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N.,\\nBrockman, G., et al. (2021). Evaluating large language models trained on code. arXiv:2107.03374 .\\nChiang, T. (2023). ChatGPT is a blurry JPEG of the web.\\nDavison, R. M., Laumer, S., Tarafdar, M., and Wong, L. H. M. (2023). ISJeditorial: Pickled eggs:\\nGenerative AI as research assistant or co-author? Inf. Syst. J. , early view.\\nDe-Arteaga, M., Feuerriegel, S., and Saar-Tsechansky, M. (2022). Algorithmic fairness in busi-\\nness analytics: Directions for research and practice. Production and Operations Management ,\\n31(10):3749–3770.\\nDebortoli, S., Müller, O., and vom Brocke, J. (2014). Comparing business intelligence and big data\\nskills. Business & Information Systems Engineering , 6(5):289–300.\\n23Dellermann, D., Ebel, P., Söllner, M., and Leimeister, J. M. (2019). Hybrid intelligence. Business &\\nInformation Systems Engineering , 61(5):637–643.\\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2018). BERT: Pre-training of deep bidirectional\\ntransformers for language understanding. arXiv:1810.04805 .\\nDiederich, S., Brendel, A. B., and Kolbe, L. M. (2020). Designing anthropomorphic enterprise conver-\\nsational agents. Business & Information Systems Engineering , 62(3):193–209.\\nDietz, M. and Pernul, G. (2020). Digital Twin: Empowering Enterprises Towards a System-of-Systems\\nApproach. Business & Information Systems Engineering , 62(2):179–184.\\nDolata, M., Feuerriegel, S., and Schwabe, G. (2022). A sociotechnical view of algorithmic fairness.\\nInformation Systems Journal , 32(4):754–818.\\nDwivedi, Y. K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., Baabdullah, A. M.,\\nKoohang, A., Raghavan, V., Ahuja, M., et al. (2023). So what if ChatGPT wrote it? Multidisci-\\nplinary perspectives on opportunities, challenges and implications of generative conversational AI\\nfor research, practice and policy. International Journal of Information Management , 71:102642.\\nEloundou, T., Manning, S., Mishkin, P., and Rock, D. (2023). GPTs are GPTs: An early look at the labor\\nmarket impact potential of large language models.\\nEskreis-Winkler, L. and Fishbach, A. (2022). Surprised elaboration: When white men get longer sen-\\ntences. Journal of Personality and Social Psychology .\\nFerrara, E. (2023). Should ChatGPT be biased? Challenges and risks of bias in large language models.\\narXiv:2304.03738 .\\nFeuerriegel, S., Dolata, M., and Schwabe, G. (2020). Fair AI: Challenges and opportunities. Business &\\nInformation Systems Engineering , 62:379–384.\\nFeuerriegel, S., Shrestha, Y. R., von Krogh, G., and Zhang, C. (2022). Bringing artiﬁcial intelligence to\\nbusiness management. Nature Machine Intelligence , 4(7):611–613.\\nFill, H.-G., Fettke, P., and Köpke, J. (2023). Conceptual Modeling and Large Language Models: Im-\\npressions From First Experiments With ChatGPT. Enterprise Modelling and Information Systems\\nArchitectures (EMISAJ) , 18(3):1–15.\\nGanguli, D., Askell, A., Schiefer, N., Liao, T., Lukoši ¯ut˙e, K., Chen, A., Goldie, A., Mirhoseini, A.,\\nOlsson, C., Hernandez, D., et al. (2023). The capacity for moral self-correction in large language\\nmodels. arXiv:2302.07459 .\\nGarcia, T. (2023). David Guetta replicated Eminem’s voice in a song using artiﬁcial intelligence.\\nGilardi, F., Alizadeh, M., and Kubli, M. (2023). ChatGPT outperforms crowd-workers for text-\\nannotation tasks. arXiv:2303.15056 .\\nGimpel, H., Hall, K., Decker, S., Eymann, T., Lämmermann, L., Mädche, A., Röglinger, M., Ruiner, C.,\\nSchoch, M., Schoop, M., et al. (2023). Unlocking the power of generative ai models and systems\\nsuch as GPT-4 and ChatGPT for higher education.\\nGoldman Sachs (2023). Generative AI could raise global GDP by 7%. https://\\nwww.goldmansachs.com/insights/pages/generative-ai-could-raise-global-gdp\\n-by-7-percent.html .\\nGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and\\nBengio, Y. (2014). Generative adversarial nets. Advances in Neural Information Processing Sys-\\ntems, 27:2672–2680.\\nGray, H. M., Gray, K., and Wegner, D. M. (2007). Dimensions of mind perception. Science ,\\n315(5812):619–619.\\nGrisold, T., GroSS, S., Stelzl, K., vom Brocke, J., Mendling, J., Röglinger, M., and Rosemann, M.\\n(2022). The ﬁve diamond method for explorative business process management. Business &\\nInformation Systems Engineering , 64(2):149–166.\\nHaag, S. and Eckhardt, A. (2017). Shadow IT. Business & Information Systems Engineering , 59(6):469–\\n473.\\nHaase, J. and Hanel, P. H. P. (2023). Artiﬁcial muses: Generative artiﬁcial intelligence chatbots have\\nrisen to human-level creativity. arXiv:2303.12003 .\\nHartmann, J., Bergner, A., and Hildebrand, C. (2023a). MindMiner: Uncovering linguistic markers\\n24of mind perception as a new lens to understand consumer-smart object relationships. Journal of\\nConsumer Psychology , Forthcoming.\\nHartmann, J., Schwenzow, J., and Witte, M. (2023b). The political ideology of conversational AI: Con-\\nverging evidence on ChatGPT’s pro-environmental, left-libertarian orientation. arXiv:2301.01768 .\\nHawlitschek, F. (2023). Interview with Samuel Tschepe on Quo vadis design thinking?. Business &\\nInformation Systems Engineering , 65(2):223–228.\\nHerm, L.-V., Janiesch, C., Reijers, H. A., and Seubert, F. (2021). From symbolic RPA to intelligent RPA:\\nchallenges for developing and operating intelligent software robots. In International Conference\\non Business Process Management , pages 289–305.\\nHevner, A., vom Brocke, J., and Maedche, A. (2019). Roles of digital innovation in design science\\nresearch. Business & Information Systems Engineering , 61(1):3–8.\\nHo, J., Jain, A., and Abbeel, P. (2020). Denoising diffusion probabilistic models. Advances in Neural\\nInformation Processing Systems , 33:6840–6851.\\nJakesch, M., French, M., Ma, X., Hancock, J. T., and Naaman, M. (2019). AI-mediated communication:\\nHow the perception that proﬁle text was written by AI affects trustworthiness. In Conference on\\nHuman Factors in Computing Systems (CHI) .\\nJakesch, M., Hancock, J. T., and Naaman, M. (2023). Human heuristics for AI-generated language are\\nﬂawed. Proceedings of the National Academy of Sciences , 120(11):e2208839120.\\nJaniesch, C., Zschech, P., and Heinrich, K. (2021). Machine learning and deep learning. Electronic\\nMarkets , 31(3):685–695.\\nJi, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y. J., Madotto, A., and Fung, P. (2023).\\nSurvey of hallucination in natural language generation. ACM Computing Surveys , 55(12):1–38.\\nKasneci, E., Seßler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G.,\\nGünnemann, S., Hüllermeier, E., et al. (2023). ChatGPT for good? On opportunities and chal-\\nlenges of large language models for education. Learning and Individual Differences , 103:102274.\\nKecht, C., Egger, A., Kratsch, W., and Röglinger, M. (2023). Quantifying chatbots ability to learn\\nbusiness processes. Information Systems , 113:102176.\\nKhan, J. (2021). AIs carbon footprint is big, but easy to reduce, Google researchers say. Fortune .\\nKingma, D. P. and Welling, M. (2013). Auto-encoding variational Bayes.\\nKlotz, S., Kopper, A., Westner, M., and Strahringer, S. (2022). Von Schatten-IT zu Business-managed\\nIT: Fachbereichs-IT gezielt gestalten. Wirtschaftsinformatik & Management , 14(4):282–287.\\nKraus, M., Feuerriegel, S., and Oztekin, A. (2020). Deep learning in business analytics and operations\\nresearch: Models, applications and managerial implications. European Journal of Operational\\nResearch , 281(3):628–641.\\nKreps, S., McCain, R. M., and Brundage, M. (2022). All the news thats ﬁt to fabricate: AI-generated\\ntext as a tool of media misinformation. Journal of Experimental Political Science , 9(1):104–117.\\nKrügel, S., Ostermaier, A., and Uhl, M. (2023). ChatGPTs inconsistent moral advice inﬂuences users\\njudgment. Scientiﬁc Reports , 13(1):4569.\\nLasi, H., Fettke, P., Kemper, H.-G., Feld, T., and Hoffmann, M. (2014). Industry 4.0. Business &\\nInformation Systems Engineering , 6(4):239–242.\\nLi, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., Eccles, T., Keeling, J., Gimeno,\\nF., Dal Lago, A., et al. (2022). Competition-level code generation with alphacode. Science ,\\n378(6624):1092–1097.\\nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G. (2023). Pre-train, prompt, and predict: A\\nsystematic survey of prompting methods in natural language processing. ACM Computing Surveys ,\\n55(9):1–35.\\nLongoni, C., Fradkin, A., Cian, L., and Pennycook, G. (2022). News from generative artiﬁcial intelli-\\ngence is believed less. In ACM Conference on Fairness, Accountability, and Transparency (FAccT) ,\\npages 97–106.\\nMaarouf, A., Bär, D., Geissler, D., and Feuerriegel, S. (2023). Hqp: A human-annotated dataset for\\ndetecting online propaganda. arXiv:2304.14931 .\\nMaedche, A., Legner, C., Benlian, A., Berger, B., Gimpel, H., Hess, T., Hinz, O., Morana, S., and\\n25Söllner, M. (2019). AI-based digital assistants: Opportunities, threats, and research perspectives.\\nBusiness & Information Systems Engineering , 61(4):535–544.\\nMaedche, A., Morana, S., Schacht, S., Werth, D., and Krumeich, J. (2016). Advanced user assistance\\nsystems. Business & Information Systems Engineering , 58:367–370.\\nMatz, S., Teeny, J., Vaid, S. S., Harari, G. M., and Cerf, M. (2023). The potential of generative AI for\\npersonalized persuasion at scale. PsyArXiv .\\nMatz, S. C., Kosinski, M., Nave, G., and Stillwell, D. J. (2017). Psychological targeting as an ef-\\nfective approach to digital mass persuasion. Proceedings of the National Academy of Sciences ,\\n114(48):12714–12719.\\nMetz, C. (2023). Instant videos could represent the next leap in A.I. technology.\\nMirsky, Y. and Lee, W. (2021). The creation and detection of deepfakes: A survey. ACM Computing\\nSurveys (CSUR) , 54(1):1–41.\\nMorana, S., Maedche, A., Schacht, S., and of Technology, K. I. (2019). Designing process guidance\\nsystems. Journal of the Association for Information Systems , pages 499–535.\\nNg, A. and Jordan, M. (2001). On discriminative vs. generative classiﬁers: A comparison of logistic\\nregression and naive Bayes. In Advances in Neural Information Processing Systems , volume 14,\\npages 841–848.\\nOpenAI (2022). Introducing ChatGPT. https://openai.com/blog/chatgpt .\\nOpenAI (2023a). GPT-4 technical report. arXiv:2303.08774 .\\nOpenAI (2023b). How should AI systems behave, and who should decide? https://openai.com/\\nblog/how-should-ai-systems-behave .\\nPark, J. S., O’Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S. (2023). Generative\\nagents: Interactive simulacra of human behavior. arXiv:2304.03442 .\\nPeres, R., Schreier, M., Schweidel, D., and Sorescu, A. (2023). On ChatGPT and beyond: How gen-\\nerative artiﬁcial intelligence may affect research, teaching, and practice. International Journal of\\nResearch in Marketing .\\nRabinowitz, N. C., Perbet, F., Song, H. F., Zhang, C., Eslami, S. M. A., and Botvinick, M. M. (2018).\\nMachine theory of mind. In International Conference on Machine Learning , volume 80, pages\\n4215–4224. PMLR.\\nRai, A. (2020). Explainable AI: From black box to glass box. Journal of the Academy of Marketing\\nScience , 48:137–141.\\nRamaswamy, V. and Ozcan, K. (2018). What is co-creation? An interactional creation framework and\\nits implications for value creation. Journal of Business Research , 84:196–205.\\nReisenbichler, M., Reutterer, T., Schweidel, D. A., and Dan, D. (2022). Frontiers: Supporting content\\nmarketing with natural language generation. Marketing Science , 41(3):441–452.\\nRombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B. (2022). High-resolution image\\nsynthesis with latent diffusion models. In IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition , pages 10684–10695.\\nSandkuhl, K., Fill, H., Hoppenbrouwers, S., Krogstie, J., Matthes, F., Opdahl, A. L., Schwabe, G.,\\nUludag, Ö., and Winter, R. (2018). From expert discipline to common practice: A vision and\\nresearch agenda for extending the reach of enterprise modeling. Business & Information Systems\\nEngineering , 60(1):69–80.\\nSchoormann, T., Möller, F., and Hansen, M. R. P. (2021). How do researchers (re-)use design principles:\\nAn inductive analysis of cumulative research. In The Next Wave of Sociotechnical Design , Lecture\\nNotes in Computer Science, pages 188–194, Cham. Springer.\\nSchoormann, T., Stadtländer, M., and Knackstedt, R. (2023a). Act and reﬂect: Integrating reﬂection into\\ndesign thinking. Journal of Management Information Systems , 40(1):7–37.\\nSchoormann, T., Strobel, G., Möller, F., Petrik, D., and Zschech, P. (2023b). Artiﬁcial intelligence\\nfor sustainability: A systematic review of information systems literature. Communications of the\\nAssociation for Information Systems , 52(1).\\nSchramowski, P., Turan, C., Andersen, N., Rothkopf, C. A., and Kersting, K. (2022). Large pre-trained\\nlanguage models contain human-like biases of what is right and wrong to do. Nature Machine\\n26Intelligence , 4(3):258–268.\\nSchwartz, R., Dodge, J., Smith, N. A., and Etzioni, O. (2020). Green AI. Communications of the ACM ,\\n63(12):54–63.\\nSchöbel, S., Schmitt, A., Benner, D., Saqr, M., Janson, A., and Leimeister, J. M. (2023). Charting\\nthe evolution and future of conversational agents: A research agenda along ﬁve waves and new\\nfrontiers. Information Systems Frontiers .\\nSenoner, J., Netland, T., and Feuerriegel, S. (2022). Using explainable artiﬁcial intelligence to improve\\nprocess quality: Evidence from semiconductor manufacturing. Management Science , 68(8):5704–\\n5723.\\nShin, M., Kim, J., van Opheusden, B., and Grifﬁths, T. L. (2023). Superhuman artiﬁcial intelligence can\\nimprove human decision-making by increasing novelty. Proceedings of the National Academy of\\nSciences , 120(12):e2214840120.\\nShollo, A., Hopf, K., Thiess, T., and Müller, O. (2022). Shifting ML value creation mechanisms: A\\nprocess model of ML value creation. The Journal of Strategic Information Systems , 31(3):101734.\\nSiebers, P., Janiesch, C., and Zschech, P. (2022). A survey of text representation methods and their\\ngenealogy. IEEE Access , 10:96492–96513.\\nSilva, N., Sousa, P., and Mira da Silva, M. (2021). Maintenance of enterprise architecture models.\\nBusiness & Information Systems Engineering , 63(2):157–180.\\nSlack, D., Krishna, S., Lakkaraju, H., and Singh, S. (2023). Explaining machine learning models with\\ninteractive natural language conversations using TalkToModel. Nature Machine Intelligence .\\nSmits, J. and Borghuis, T. (2022). Generative AI and intellectual property rights. In Law and Artiﬁcial\\nIntelligence: Regulating AI and Applying AI in Legal Practice , pages 323–344. Springer.\\nSpitale, G., Biller-Andorno, N., and Germani, F. (2023). AI model GPT-3 (dis) informs us better than\\nhumans. arXiv:2301.11924 .\\nStrobelt, H., Webson, A., Sanh, V., Hoover, B., Beyer, J., Pﬁster, H., and Rush, A. M. (2023). Interac-\\ntive and visual prompt engineering for ad-hoc task adaptation with large language models. IEEE\\nTransactions on Visualization and Computer Graphics , 29(1):1146–1156.\\nSusarla, A., Thatcher, R. G. J. B., and Sarker, S. (2023). Editorial: The janus effect of generative AI:\\nCharting the path for responsible conduct of scholarly activities in information systems. Inf. Syst.\\nRes., 34(2):399–408.\\nSutskever, I., Vinyals, O., and Le, Q. V. (2014). Sequence to sequence learning with neural networks.\\nAdvances in Neural Information Processing Systems , 27:3104–3112.\\nTeubner, T., Flath, C. M., Weinhardt, C., van der Aalst, W., and Hinz, O. (2023). Welcome to the era of\\nChatGPT et al. Business & Information Systems Engineering , 65(2):95–101.\\nUnsal, S., Atas, H., Albayrak, M., Turhan, K., Acar, A. C., and Do ˘gan, T. (2022). Learning functional\\nproperties of proteins with language models. Nature Machine Intelligence , 4(3):227–245.\\nvan der Aalst, W. M. P., Bichler, M., and Heinzl, A. (2018). Robotic process automation. Business &\\nInformation Systems Engineering , 60(4):269–272.\\nvan Dun, C., Moder, L., Kratsch, W., and Röglinger, M. (2023). ProcessGAN: Supporting the creation\\nof business process improvement ideas through generative machine learning. Decision Support\\nSystems , 165:113880.\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and Polosukhin,\\nI. (2017). Attention is all you need. Advances in Neural Information Processing Systems , 30:6000–\\n6010.\\nVernadat, F. (2020). Enterprise modelling: Research review and outlook. Computers in Industry ,\\n122:103265.\\nVidgof, M., Bachhofner, S., and Mendling, J. (2023). Large language models for business process\\nmanagement: Opportunities and challenges. arXiv:2304.04309 .\\nvon Zahn, M., Feuerriegel, S., and Kuehl, N. (2022). The cost of fairness in AI: Evidence from e-\\ncommerce. Business & Information Systems Engineering , 64:335–348.\\nWolfe, R., Banaji, M. R., and Caliskan, A. (2022). Evidence for hypodescent in visual semantic AI. In\\nACM Conference on Fairness, Accountability, and Transparency , pages 1293–1304.\\n27Ziegler, D. M., Stiennon, N., Wu, J., Brown, T. B., Radford, A., Amodei, D., Christiano, P., and Irving,\\nG. (2019). Fine-tuning language models from human preferences. arXiv:1909.08593 .\\nZilker, S., Weinzierl, S., Zschech, P., Kraus, M., and Matzner, M. (2023). Best of both worlds: Com-\\nbining predictive power with interpretable and explainable results for patient pathway prediction.\\nInProceedings of the 31st European Conference on Information Systems (ECIS) , Kristiansand,\\nNorway.\\nZschech, P., Horn, R., Höschele, D., Janiesch, C., and Heinrich, K. (2020). Intelligent user assis-\\ntance for automated data mining method selection. Business & Information Systems Engineering ,\\n62(3):227–247.\\n28\\nView publication stats'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WE NEED TO SPLIT THE TEXT USING CHARATER TEXT SPLITTER SUCH THAT IT SHOULD NOT INCREASE TOKEN SIZE\n",
        "text_splitter=CharacterTextSplitter(\n",
        "    separator= \"\\n\",\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "texts=text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "R-HTF5rvzmSF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vy4TroNzmPh",
        "outputId": "468b70c3-1f9c-46f8-b97f-57533fa157d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download embiddings from Open AI\n",
        "embeddings=OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "VbHUwDltzmNI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_search=FAISS.from_texts(texts,embeddings)"
      ],
      "metadata": {
        "id": "pBQ2_8qszmKi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP43tSlqzmHs",
        "outputId": "ea452a4d-e4de-4bcf-d5e7-0022e346be4f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain.vectorstores.faiss.FAISS at 0x7888cf22ba90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "14mKXo6RzmFF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain=load_qa_chain(OpenAI(),chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "GfqQk8g5z0dI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"give the summary of the pdf\"\n",
        "docs=document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs,question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "bVxrjSZ7z0aR",
        "outputId": "c158d454-6d7b-4f52-c249-ce0d6844d494"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This PDF discusses generative AI and how it is used in tasks such as image generation. It explores two types of generative AI models: diffusion probability models and reinforcement learning from human feedback (RLHF). RLHF is a three-step process which creates demonstration data for prompts, has users rank the quality of different outputs for a prompt, and learns a policy that generates desirable output via reinforcement learning.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eus01zRWz0XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h-GLEbxMz0Uc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
